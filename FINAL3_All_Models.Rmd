---
title: "Untitled"
output: html_document
date: "2024-12-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# 1. load packages
```{r}
library(dplyr)
library(glmnet)        # Ridge regression and lasso regression
library(randomForest)  # random forest
library(caret)         # Performance Evaluation
library(e1071)         # support vector machine (SVM)
library(xgboost)       # XGBoost
library(dbarts)        # BART
library(pROC)
```



# 2. load data
```{r}
# read data

### READ ME!!!
# THESE data were generated by FINAL_Model_Try.RMD
###

Binary_Injury_Location <- read.csv("Binary_and_Numeric/binary_injury_location.csv")
Binary_Injury_Method <- read.csv("Binary_and_Numeric/binary_injury_method.csv")
numeric_location <- read.csv("Binary_and_Numeric/numeric_location.csv")
numeric_method <- read.csv("Binary_and_Numeric/numeric_method.csv")
```


## 2.1. feature engineer

### 2.1.1. numeric_location

```{r}

# Game Style
numeric_location$OffensiveStyle <- numeric_location$PTS_PrGs + numeric_location$AST_PrGs + 0.5 * numeric_location$ORB_PrGs
numeric_location$DefensiveStyle <- numeric_location$STL_PrGs + numeric_location$BLK_PrGs + numeric_location$DRB_PrGs
# Work load
numeric_location$Workload <- numeric_location$MP_PrGs * numeric_location$G
# Tow or three shots choice
numeric_location$TwoPointRate <- numeric_location$X2PA_PrGs / numeric_location$FGA_PrGs
numeric_location$ThreePointRate <- numeric_location$X3PA_PrGs / numeric_location$FGA_PrGs
# Efficiency
numeric_location$ShootingEfficiency <- numeric_location$eFG._PrGs
numeric_location$LoadPerGame <- numeric_location$MP_PrGs
numeric_location$EfficiencyPerAge <- numeric_location$ShootingEfficiency/numeric_location$age_at_injury

# behavior
numeric_location$DefensiveAggressiveness <- numeric_location$STL_PrGs + numeric_location$BLK_PrGs
numeric_location$TurnoverRate <- numeric_location$TOV_PrGs / numeric_location$MP_PrGs
numeric_location$FoulRate <- numeric_location$PF_PrGs / numeric_location$MP_PrGs


numeric_location_fetr_sltd <- numeric_location %>% 
  select(age_at_injury,height_cm,weight_kg,career_before, 
         OffensiveStyle, DefensiveStyle,
         Workload,
         TwoPointRate, ThreePointRate,
         ShootingEfficiency, LoadPerGame, EfficiencyPerAge,
         DefensiveAggressiveness, TurnoverRate, FoulRate
         )
```

### 2.1.2. numeric_method

```{r}
# Game Style
numeric_method$OffensiveStyle <- numeric_method$PTS_PrGs + numeric_method$AST_PrGs + 0.5 * numeric_method$ORB_PrGs
numeric_method$DefensiveStyle <- numeric_method$STL_PrGs + numeric_method$BLK_PrGs + numeric_method$DRB_PrGs
# Work load
numeric_method$Workload <- numeric_method$MP_PrGs * numeric_method$G
# Tow or three shots choice
numeric_method$TwoPointRate <- numeric_method$X2PA_PrGs / numeric_method$FGA_PrGs
numeric_method$ThreePointRate <- numeric_method$X3PA_PrGs / numeric_method$FGA_PrGs
# Efficiency
numeric_method$ShootingEfficiency <- numeric_method$eFG._PrGs
numeric_method$LoadPerGame <- numeric_method$MP_PrGs
numeric_method$EfficiencyPerAge <- numeric_method$ShootingEfficiency / numeric_method$age_at_injury

# behavior
numeric_method$DefensiveAggressiveness <- numeric_method$STL_PrGs + numeric_method$BLK_PrGs
numeric_method$TurnoverRate <- numeric_method$TOV_PrGs / numeric_method$MP_PrGs
numeric_method$FoulRate <- numeric_method$PF_PrGs / numeric_method$MP_PrGs

numeric_method_fetr_sltd <- numeric_method %>% 
  select(age_at_injury, height_cm, weight_kg, career_before, 
         OffensiveStyle, DefensiveStyle,
         Workload,
         TwoPointRate, ThreePointRate,
         ShootingEfficiency, LoadPerGame, EfficiencyPerAge,
         DefensiveAggressiveness, TurnoverRate, FoulRate
         )

```



# Merge Data

```{r}
Location_Binary <- cbind(Binary_Injury_Location, numeric_location_fetr_sltd)
Method_Binary <- cbind(Binary_Injury_Method, numeric_method_fetr_sltd)
```

## 3.1. Replace NA with 0

```{r}
Location_Binary[is.na(Location_Binary)] <- 0
Method_Binary[is.na(Method_Binary)] <- 0

```

## 3.2. Prepare for iteration
```{r}
# Save the spliced data as a list for easy iteration
datasets <- list(
  Location_Binary = Location_Binary,
  Method_Binary = Method_Binary
)
```


# 4. fit model


```{r}
# Initialization result storage
performance_results <- data.frame()
```



```{r}
# Iterate through each dataset
for (dataset_name in names(datasets)) {
  dataset <- datasets[[dataset_name]]
  
  # Extracting column names of binary and numeric variables
  binary_cols <- colnames(dataset)[sapply(dataset, function(col) all(col %in% c(0, 1)))]
  numeric_cols <- colnames(dataset)[!colnames(dataset) %in% binary_cols]
  
  # Split data sets
  set.seed(123)  
  train_indices <- sample(1:nrow(dataset), size = 0.7 * nrow(dataset))
  train_data <- dataset[train_indices, ]
  test_data <- dataset[-train_indices, ]
  
  # Iterate over each binary variable (as a target variable)
  for (binary_col in binary_cols) {
    # Extraction of training and test features and target variables
    X_train <- train_data[, numeric_cols, drop = FALSE]
    y_train <- train_data[[binary_col]]
    X_test <- test_data[, numeric_cols, drop = FALSE]
    y_test <- test_data[[binary_col]]
    
    performance <- data.frame(
      Variable = binary_col,
      Dataset = dataset_name,
      Logistic_Accuracy = NA, Logistic_Recall = NA, Logistic_Precision = NA, Logistic_AUC = NA, Logistic_Kappa = NA, 
      Ridge_Accuracy = NA, Ridge_Recall = NA, Ridge_Precision = NA, Ridge_AUC = NA, Ridge_Kappa = NA, 
      Lasso_Accuracy = NA, Lasso_Recall = NA, Lasso_Precision = NA, Lasso_AUC = NA, Lasso_Kappa = NA, 
      RF_Accuracy = NA, RF_Recall = NA, RF_Precision = NA,  RF_Kappa = NA, 
      BART_Accuracy = NA, BART_Recall = NA, BART_Precision = NA,  BART_Kappa = NA, 
      SVM_Accuracy = NA, SVM_Recall = NA, SVM_Precision = NA,  SVM_Kappa = NA, 
      XGB_Accuracy = NA, XGB_Recall = NA, XGB_Precision = NA,  XGB_Kappa = NA
    )
    
    ### logistic regression
    logistic_model <- glm(y_train ~ ., data = as.data.frame(X_train), family = binomial)
    logistic_preds <- predict(logistic_model, newdata = as.data.frame(X_test), type = "response")
    logistic_classes <- ifelse(logistic_preds > 0.5, 1, 0)
    logistic_metrics <- confusionMatrix(factor(logistic_classes), factor(y_test))
    performance$Logistic_Accuracy <- logistic_metrics$overall["Accuracy"]
    performance$Logistic_Recall <- logistic_metrics$byClass["Recall"]
    performance$Logistic_Precision <- logistic_metrics$byClass["Precision"]
    performance$Logistic_Kappa <- logistic_metrics$overall["Kappa"]

    logistic_roc <- roc(response = as.numeric(y_test), predictor = logistic_preds)
    performance$Logistic_AUC <- auc(logistic_roc)

    
    ### Ridge regression
    ridge_model <- cv.glmnet(as.matrix(X_train), y_train, family = "binomial", alpha = 0)
    ridge_preds <- predict(ridge_model, newx = as.matrix(X_test), s = "lambda.min", type = "response")
    ridge_classes <- ifelse(ridge_preds > 0.5, 1, 0)
    ridge_metrics <- confusionMatrix(factor(ridge_classes), factor(y_test))
    performance$Ridge_Recall <- ridge_metrics$byClass["Recall"]
    performance$Ridge_Accuracy <- ridge_metrics$overall["Accuracy"]
    performance$Ridge_Precision <- ridge_metrics$byClass["Precision"]
    performance$Ridge_Kappa <- ridge_metrics$overall["Kappa"]

    Ridge_roc <- roc(response = as.numeric(y_test), predictor = ridge_preds)
    performance$Ridge_AUC <- auc(Ridge_roc)
    
    ### lasso regression
    lasso_model <- cv.glmnet(as.matrix(X_train), y_train, family = "binomial", alpha = 1)
    lasso_preds <- predict(lasso_model, newx = as.matrix(X_test), s = "lambda.min", type = "response")
    lasso_classes <- ifelse(lasso_preds > 0.5, 1, 0)
    lasso_metrics <- confusionMatrix(factor(lasso_classes), factor(y_test))
    performance$Lasso_Recall <- lasso_metrics$byClass["Recall"]
    performance$Lasso_Accuracy <- lasso_metrics$overall["Accuracy"]
    performance$Lasso_Precision <- lasso_metrics$byClass["Precision"]
    performance$Lasso_Kappa <- lasso_metrics$overall["Kappa"]

    Lasso_roc <- roc(response = as.numeric(y_test), predictor = lasso_preds)
    performance$Lasso_AUC <- auc(Lasso_roc)
    
    ### Random forest
    rf_model <- randomForest(x = X_train, y = factor(y_train), ntree = 100, mtry = sqrt(ncol(X_train)))
    rf_preds <- predict(rf_model, newdata = X_test)
    rf_metrics <- confusionMatrix(rf_preds, factor(y_test))
    performance$RF_Recall <- rf_metrics$byClass["Recall"]
    performance$RF_Accuracy <- rf_metrics$overall["Accuracy"]
    performance$RF_Precision <- rf_metrics$byClass["Precision"]
    performance$RF_Kappa <- rf_metrics$overall["Kappa"]

    
    ### BART
    bart_model <- dbarts::bart(
      x.train = as.matrix(X_train),
      y.train = as.numeric(y_train),
      x.test = as.matrix(X_test),
      keeptrees = TRUE
    )
    bart_preds <- predict(bart_model, newdata = as.matrix(X_test))
    bart_preds_transposed <- t(bart_preds)
    bart_preds_mean <- rowMeans(bart_preds_transposed)
    bart_classes <- ifelse(bart_preds_mean > 0.5, 1, 0)
    bart_metrics <- confusionMatrix(factor(bart_classes), factor(y_test))
    performance$BART_Recall <- bart_metrics$byClass["Recall"]
    performance$BART_Accuracy <- bart_metrics$overall["Accuracy"]
    performance$BART_Precision <- bart_metrics$byClass["Precision"]
    performance$BART_Kappa <- bart_metrics$overall["Kappa"]

    
    ### SVM
    svm_model <- svm(x = X_train, y = factor(y_train), kernel = "radial", probability = TRUE)
    svm_preds <- predict(svm_model, X_test, probability = TRUE)
    svm_metrics <- confusionMatrix(svm_preds, factor(y_test))
    performance$SVM_Recall <- svm_metrics$byClass["Recall"]
    performance$SVM_Accuracy <- svm_metrics$overall["Accuracy"]
    performance$SVM_Precision <- svm_metrics$byClass["Precision"]
    performance$SVM_Kappa <- svm_metrics$overall["Kappa"]

    
    ### XGBoost
    dtrain <- xgb.DMatrix(data = as.matrix(X_train), label = as.numeric(y_train))
    dtest <- xgb.DMatrix(data = as.matrix(X_test))
    xgb_model <- xgboost(data = dtrain, max_depth = 6, eta = 0.3, nrounds = 50, objective = "binary:logistic", verbose = 0)
    xgb_preds <- predict(xgb_model, newdata = dtest)
    xgb_classes <- ifelse(xgb_preds > 0.5, 1, 0)
    xgb_metrics <- confusionMatrix(factor(xgb_classes), factor(y_test))
    performance$XGB_Recall <- xgb_metrics$byClass["Recall"]
    performance$XGB_Accuracy <- xgb_metrics$overall["Accuracy"]
    performance$XGB_Precision <- xgb_metrics$byClass["Precision"]
    performance$XGB_Kappa <- xgb_metrics$overall["Kappa"]

    
    # SAVE
    performance_results <- rbind(performance_results, performance)
  }
}

# VIEW the results
print(performance_results)
```



```{r}
#write.csv(Location_Binary, "Location_Bin_Num_fetr_sltd.csv", row.names = FALSE)

```





